//
//  encoder.swift
//  ffconverter
//
//  Created by rei8 on 2019/09/07.
//  Copyright Â© 2019 lithium03. All rights reserved.
//

import Foundation
import AVFoundation
import CoreMedia
import VideoToolbox
import CoreAudio

class Encoder {
    let width = 1920
    let height = 1080
    //let width = 1280
    //let height = 720

    var compressionSession: VTCompressionSession?
    var pxbuffer: CVPixelBuffer?

    var audio_count: Int = -1
    var subtitle_count: Int = -1
    var audios: [sound_processer] = []
    var writer: [TS_writer?] = []
    var subwriter: [WebVTTwriter?] = []
    let dest: URL
    var isLive = true

    var onReady: (()->Void)?
    
    class sound_processer {
        let sound_fq = 48000.0
        let ch: Int

        var lpcmToAACConverter: AVAudioConverter? = nil
        var sound_buffer = Data()
        var sound_RDBs: [Data] = []
        var sound_pts: Double? = nil

        init(channel: Int) {
            ch = channel
        }
        
        func process_sound(writer: TS_writer?, final: Bool = false) {
            autoreleasepool {
                let outFormat: [String: Any] = [
                    AVFormatIDKey: kAudioFormatMPEG4AAC,
                    AVSampleRateKey: sound_fq,
                    AVNumberOfChannelsKey: 2,
                    AVEncoderBitRatePerChannelKey: 320000,
                    AVEncoderBitRateStrategyKey: AVAudioBitRateStrategy_Variable,
                ]
                guard let outputFormat = AVAudioFormat(settings: outFormat) else {
                    return
                }
                
                guard let inputFormat = AVAudioFormat(commonFormat: .pcmFormatFloat32, sampleRate: sound_fq, channels: 2, interleaved: true) else {
                    return
                }
                
                //init converter once
                if lpcmToAACConverter == nil {
                    lpcmToAACConverter = AVAudioConverter(from: inputFormat, to: outputFormat)
                }
                let outBuffer = AVAudioCompressedBuffer(format: outputFormat, packetCapacity: 1, maximumPacketSize: 1024 * 2)
                
                let inputBlock : AVAudioConverterInputBlock = { (inNumPackets, outStatus) -> AVAudioBuffer? in
                    outStatus.pointee = .noDataNow
                    let sample_size = MemoryLayout<Float>.size * 2
                    if self.sound_buffer.count <= (final ? 0 : sample_size * 1024) {
                        return nil
                    }
                    var samples = self.sound_buffer.count / sample_size
                    if samples > 1024 {
                        samples = 1024
                    }
                    guard let inputBuffer = AVAudioPCMBuffer(pcmFormat: inputFormat, frameCapacity: AVAudioFrameCount(samples)) else {
                        return nil
                    }
                    guard let target = inputBuffer.floatChannelData else {
                        return nil
                    }
                    let _ = self.sound_buffer.withUnsafeBytes { wav_data in
                        memcpy(target.pointee, wav_data.baseAddress, samples*sample_size)
                    }
                    self.sound_buffer = self.sound_buffer.subdata(in: (samples*sample_size)..<self.sound_buffer.count)
                    inputBuffer.frameLength = inputBuffer.frameCapacity
                    outStatus.pointee = AVAudioConverterInputStatus.haveData
                    let audioBuffer : AVAudioBuffer = inputBuffer
                    return audioBuffer
                }
                var status: AVAudioConverterOutputStatus?
                var error : NSError?
                
                repeat {
                    status = lpcmToAACConverter?.convert(to: outBuffer, error: &error, withInputFrom: inputBlock)
                    
                    if outBuffer.byteLength > 0 {
                        var data = [UInt8](repeating: 0, count: Int(outBuffer.byteLength))
                        data.withUnsafeMutableBufferPointer { p in
                            let _ = memcpy(p.baseAddress, outBuffer.data, Int(outBuffer.byteLength))
                        }
                        
                        sound_RDBs += [Data(data)]
                    }
                } while status == .haveData
                
                var spts: CMTime? = nil
                if let pts = self.sound_pts {
                    spts = CMTime(seconds: pts, preferredTimescale: CMTimeScale(self.sound_fq))
                }
                for RDBblock in sound_RDBs {
                    var PESdata = Data()
                    let len = RDBblock.count
                    PESdata.append(0xFF)
                    PESdata.append(0xF1)
                    let profile = 2  //AAC LC
                    let freqIdx = self.sound_fq == 48000 ? 3 : 4 //3:48kHz, 4:44.1kHz
                    let chanCfg = 2  //L R
                    let adtsLength = 7
                    let fullLength = adtsLength + len
                    PESdata.append(UInt8(((profile-1)<<6)|(freqIdx<<2)|(chanCfg>>2)))
                    PESdata.append(UInt8(((chanCfg&3)<<6)|((fullLength&0x1800)>>11)))
                    PESdata.append(UInt8(((fullLength&0x7FF) >> 3)))
                    PESdata.append(UInt8((((fullLength&7)<<5)|0x1F)))
                    PESdata.append(0xFC)
                    PESdata.append(RDBblock)

                    writer?.write_audio(PS_stream: PESdata, PTS: spts, index: 0)
                    if spts != nil {
                        spts = spts! + CMTime(seconds: 1024/self.sound_fq, preferredTimescale: CMTimeScale(self.sound_fq))
                    }
                }
                sound_RDBs = []
            }
        }
    }
    
    init?(dest: URL) {
        self.dest = dest

        var formatHint: CMFormatDescription? = nil
        var status = CMVideoFormatDescriptionCreate(allocator: nil, codecType: kCMVideoCodecType_H264, width: Int32(width), height: Int32(height), extensions: nil, formatDescriptionOut: &formatHint)
        guard status == noErr else {
            return nil
        }

        let sourceImageBufferAttributes = [
            //kCVPixelBufferPixelFormatTypeKey: Int(kCVPixelFormatType_422YpCbCr8FullRange),
            kCVPixelBufferPixelFormatTypeKey: Int(kCVPixelFormatType_32BGRA),
            kCVPixelBufferWidthKey: Int(width),
            kCVPixelBufferHeightKey: Int(height),
            ] as CFDictionary
        status = VTCompressionSessionCreate(allocator: nil, width: Int32(width), height: Int32(height), codecType: CMVideoCodecType(kCMVideoCodecType_H264), encoderSpecification: nil, imageBufferAttributes: sourceImageBufferAttributes, compressedDataAllocator: nil, outputCallback: self.vt_compression_callback, refcon: unsafeBitCast(self, to: UnsafeMutableRawPointer.self), compressionSessionOut: &self.compressionSession)
        guard status == noErr else {
            return nil
        }
        
        let properties = [
            //kVTCompressionPropertyKey_RealTime: true,
            kVTCompressionPropertyKey_AverageBitRate: 5*1024*1024,
            kVTCompressionPropertyKey_AllowOpenGOP: false,
            kVTCompressionPropertyKey_ProfileLevel: kVTProfileLevel_H264_High_4_1,
            kVTCompressionPropertyKey_MaxKeyFrameIntervalDuration: 5.0,
            ] as CFDictionary
        status = VTSessionSetProperties(self.compressionSession!, propertyDictionary: properties)
        guard status == noErr else {
            return nil
        }
        
        VTCompressionSessionPrepareToEncodeFrames(self.compressionSession!)
        
        status = CVPixelBufferCreate(nil, width, height, kCVPixelFormatType_32BGRA, nil, &pxbuffer)
        guard status == noErr else {
            return nil
        }
    }
    
    func set_streamCount(audio_lng: [String], audio_main: Int, subtitle_lng: [String], subtitle_main: Int) {
        audio_count = audio_lng.count
        subtitle_count = subtitle_lng.count
        audios.removeAll()
        writer.removeAll()
        for i in 0...audio_count {
            if i > 0 {
                audios += [sound_processer(channel: i)]
            }
            let p = dest.appendingPathComponent("\(i)", isDirectory: true)
            do {
                try FileManager.default.createDirectory(at: p, withIntermediateDirectories: true, attributes: nil)
            } catch {
                return
            }
            let w = TS_writer(dest: p, split_time: 4.0, time_hint: 12.0)
            if i == 0 {
                w.set_channel(video: 1, audio: 0)
            }
            else {
                w.set_channel(video: 0, audio: 1)
            }
            writer += [w]
        }
        if subtitle_count > 0 {
            for i in (audio_count+1)...(audio_count+subtitle_count) {
                let p = dest.appendingPathComponent("\(i)", isDirectory: true)
                do {
                    try FileManager.default.createDirectory(at: p, withIntermediateDirectories: true, attributes: nil)
                } catch {
                    return
                }
                let wt = WebVTTwriter(dest: p, split_time: 10.0, time_hint: 20.0)
                subwriter += [wt]
            }
        }
        
        var content = [
            "#EXTM3U",
            "#EXT-X-VERSION:3",
            "#EXT-X-INDEPENDENT-SEGMENTS",
        ]
        let astr = FrameworkResource.getLocalized(key: "Audio")
        for i in 1...audio_count {
            let langstr = FrameworkResource.getLocalized(key: audio_lng[i-1])
            if i == audio_main+1 {
                content += ["#EXT-X-MEDIA:TYPE=AUDIO,GROUP-ID=\"aac\",LANGUAGE=\"\(audio_lng[i-1])\",NAME=\"\(astr)\(i): \(langstr)\",AUTOSELECT=YES,DEFAULT=YES,URI=\"\(i)/stream.m3u8\""]
            }
            else {
                content += ["#EXT-X-MEDIA:TYPE=AUDIO,GROUP-ID=\"aac\",LANGUAGE=\"\(audio_lng[i-1])\",NAME=\"\(astr)\(i): \(langstr)\",AUTOSELECT=YES,DEFAULT=NO,URI=\"\(i)/stream.m3u8\""]
            }
        }
        var sub_str = ""
        if subtitle_count > 0 {
            let sstr = FrameworkResource.getLocalized(key: "Subtitle")
            for i in 0..<subtitle_count {
                let langstr = FrameworkResource.getLocalized(key: subtitle_lng[i])
                let sid = audio_count+1+i
                if i == subtitle_main {
                    content += ["#EXT-X-MEDIA:TYPE=SUBTITLES,GROUP-ID=\"subs\",LANGUAGE=\"\(subtitle_lng[i])\",NAME=\"\(sstr)\(i+1): \(langstr)\",AUTOSELECT=YES,DEFAULT=YES,URI=\"\(sid)/stream.m3u8\""]
                }
                else {
                    content += ["#EXT-X-MEDIA:TYPE=SUBTITLES,GROUP-ID=\"subs\",LANGUAGE=\"\(subtitle_lng[i])\",NAME=\"\(sstr)\(i+1): \(langstr)\",AUTOSELECT=YES,DEFAULT=NO,URI=\"\(sid)/stream.m3u8\""]
                }
            }
            sub_str = ",SUBTITLES=\"subs\""
        }
        content += [
            "#EXT-X-STREAM-INF:BANDWIDTH=50000000,CODECS=\"avc1.640029, mp4a.40.5\",RESOLUTION=\(width)x\(height),AUDIO=\"aac\"\(sub_str)",
            "0/stream.m3u8"
            ]
        
        DispatchQueue.global().async {
            while self.isLive {
                var done = true
                for i in 0...(self.audio_count+self.subtitle_count) {
                    let p = self.dest.appendingPathComponent("\(i)", isDirectory: true)
                    if !FileManager.default.fileExists(atPath: p.appendingPathComponent("stream.m3u8").path) {
                        done = false
                        break
                    }
                }
                
                if !done {
                    sleep(1)
                    continue
                }
                break
            }
            
            let m3u8file = OutputStream(url: self.dest.appendingPathComponent("stream.m3u8"), append: false)
            m3u8file?.open()
            defer {
                m3u8file?.close()
            }
            let str = content.joined(separator: "\r\n") + "\r\n"
            let data = Array(str.utf8)
            m3u8file?.write(data, maxLength: data.count)
            
            let onReady = self.onReady
            DispatchQueue.global().asyncAfter(wallDeadline: .now()+1) {
                onReady?()
            }
        }
    }
    
    func encode_frame(src_data: UnsafeMutablePointer<UInt8>?, src_linesize: Int32, src_height: Int32, pts: Double, key: Bool) {
        guard let pxbuffer = pxbuffer else {
            return
        }
        guard let compressionSession = compressionSession else {
            return
        }
        var status = CVPixelBufferLockBaseAddress(pxbuffer, .init(rawValue: 0))
        guard status == noErr else {
            return
        }
        do {
            defer {
                CVPixelBufferUnlockBaseAddress(pxbuffer, .init(rawValue: 0))
            }
            let data = CVPixelBufferGetBaseAddress(pxbuffer)
            let linesize = CVPixelBufferGetBytesPerRow(pxbuffer)
            let pxheight = CVPixelBufferGetHeight(pxbuffer)
            guard src_linesize == linesize, src_height == pxheight else {
                return
            }
            let size = pxheight * linesize
            memcpy(data, src_data, size)
        }
        //print(pts, key)
        let properties = [
            kVTEncodeFrameOptionKey_ForceKeyFrame: key,
            ] as CFDictionary
        status = VTCompressionSessionEncodeFrame(
            compressionSession,
            imageBuffer: pxbuffer,
            presentationTimeStamp: CMTime(seconds: pts, preferredTimescale: 90000),
            duration: .invalid,
            frameProperties: properties,
            sourceFrameRefcon: nil,
            infoFlagsOut: nil)
        
        for sub in subwriter {
            sub?.split_check(pts: pts)
        }
    }
    
    func encode_sound(channel: Int, pcm_data: UnsafeBufferPointer<UInt8>, pts: Double) {
        audios[channel].sound_buffer.append(pcm_data)
        let sample_size = Double(MemoryLayout<Float>.size)
        audios[channel].sound_pts = pts - Double(audios[channel].sound_buffer.count)/(sample_size*2)/audios[channel].sound_fq
        if audios[channel].sound_buffer.count < Int(0.1*sample_size*2*audios[channel].sound_fq) {
            return
        }
        audios[channel].process_sound(writer: writer[channel+1])
    }
    
    func encode_text(channel: Int, text: String, pts_start: Double, pts_end: Double) {
        subwriter[channel]?.write_text(caption: text, pts_start: pts_start, pts_end: pts_end)
    }
    
    func finish_encode() {
        print("finish_encode()")
        DispatchQueue.global().async {
            guard let compressionSession = self.compressionSession else {
                return
            }
            VTCompressionSessionCompleteFrames(compressionSession, untilPresentationTimeStamp: .invalid)
            VTCompressionSessionInvalidate(compressionSession)
            self.compressionSession = nil
            
            if self.audio_count >= 0 {
                for channel in 0...self.audio_count {
                    if let writer = self.writer[channel] {
                        if channel > 0 {
                            self.audios[channel-1].process_sound(writer: writer, final: true)
                        }
                        writer.finalize()
                    }
                }
            }
            if self.subtitle_count > 0 {
                for i in 0..<self.subtitle_count {
                    if let writer = self.subwriter[i] {
                        writer.finalize()
                    }
                }
            }
        }
    }
    
    var vt_compression_callback:VTCompressionOutputCallback = {(outputCallbackRefCon: UnsafeMutableRawPointer?, sourceFrameRefCon: UnsafeMutableRawPointer?, status: OSStatus, infoFlags: VTEncodeInfoFlags, sampleBuffer: CMSampleBuffer?) in
        
        autoreleasepool {
            let encoder: Encoder = unsafeBitCast(outputCallbackRefCon, to: Encoder.self)
            guard status == noErr else {
                print(status)
                return
            }
            var elementaryStream = Data()
            if let frame = sampleBuffer {
                // Find out if the sample buffer contains an I-Frame.
                // If so we will write the SPS and PPS NAL units to the elementary stream.
                var isIFrame = false
                if let attachmentsArray = CMSampleBufferGetSampleAttachmentsArray(frame, createIfNecessary: false), CFArrayGetCount(attachmentsArray) > 0 {
                    let dict = unsafeBitCast(CFArrayGetValueAtIndex(attachmentsArray, 0), to: CFDictionary.self)
                    if let dict = dict as? [String: AnyObject] {
                        if let notSync = dict[kCMSampleAttachmentKey_NotSync as String] as? Bool {
                            isIFrame = !notSync
                        }
                        else {
                            isIFrame = true
                        }
                    }
                }
                
                // This is the start code that we will write to
                // the elementary stream before every NAL unit
                let startCode: [UInt8] = [0x00, 0x00, 0x00, 0x01]
                let startCodeLength = startCode.count
                
                elementaryStream.append(contentsOf: startCode)
                elementaryStream.append(0x09)
                elementaryStream.append(0xf0)

                // Write the SPS and PPS NAL units to the elementary stream before every I-Frame
                if isIFrame, let description = CMSampleBufferGetFormatDescription(frame) {
                    var numberOfParameterSets = 0
                    CMVideoFormatDescriptionGetH264ParameterSetAtIndex(description, parameterSetIndex: 0, parameterSetPointerOut: nil, parameterSetSizeOut: nil, parameterSetCountOut: &numberOfParameterSets, nalUnitHeaderLengthOut: nil)
                    
                    // Write each parameter set to the elementary stream
                    for i in 0..<numberOfParameterSets {
                        var parameterSetPointer: UnsafePointer<UInt8>?
                        var parameterSetLength = 0
                        CMVideoFormatDescriptionGetH264ParameterSetAtIndex(description, parameterSetIndex: i, parameterSetPointerOut: &parameterSetPointer, parameterSetSizeOut: &parameterSetLength, parameterSetCountOut: nil, nalUnitHeaderLengthOut: nil)
                        
                        // Write the parameter set to the elementary stream
                        if let parameterSetPointer = parameterSetPointer {
                            elementaryStream.append(contentsOf: startCode)
                            elementaryStream.append(parameterSetPointer, count: parameterSetLength)
                        }
                    }
                }
                
                // Get a pointer to the raw AVCC NAL unit data in the sample buffer
                var blockBufferLength = 0
                var bufferDataPointer: UnsafeMutablePointer<Int8>?
                if let block = CMSampleBufferGetDataBuffer(frame) {
                    CMBlockBufferGetDataPointer(block, atOffset: 0, lengthAtOffsetOut: nil, totalLengthOut: &blockBufferLength, dataPointerOut: &bufferDataPointer)
                }
                bufferDataPointer?.withMemoryRebound(to: UInt8.self, capacity: blockBufferLength) { bufferDataPointer in
                    // Loop through all the NAL units in the block buffer
                    // and write them to the elementary stream with
                    // start codes instead of AVCC length headers
                    var bufferOffset = 0
                    let AVCCHeaderLength = 4
                    while bufferOffset < blockBufferLength - AVCCHeaderLength {
                        // Read the NAL unit length
                        var NALUnitLength = UInt32(0)
                        memcpy(&NALUnitLength, bufferDataPointer + bufferOffset, AVCCHeaderLength);
                        // Convert the length value from Big-endian to Little-endian
                        NALUnitLength = CFSwapInt32BigToHost(NALUnitLength);
                        // Write start code to the elementary stream
                        elementaryStream.append(contentsOf: startCode)
                        // Write the NAL unit without the AVCC length header to the elementary stream
                        autoreleasepool {
                            var NALunit = [UInt8](repeating: 0, count: Int(NALUnitLength))
                            NALunit.withUnsafeMutableBufferPointer { p in
                                let _ = memcpy(p.baseAddress, bufferDataPointer + bufferOffset + AVCCHeaderLength, Int(NALUnitLength))
                            }
                            elementaryStream.append(contentsOf: NALunit)
                        }
                        // Move to the next NAL unit in the block buffer
                        bufferOffset += AVCCHeaderLength + Int(NALUnitLength);
                    }
                }
                
                let pts_frame = CMSampleBufferGetPresentationTimeStamp(frame)
                let dts_frame = CMSampleBufferGetDecodeTimeStamp(frame)
                
                let pts: CMTime?
                if CMTIME_IS_VALID(pts_frame) {
                    pts = pts_frame
                }
                else {
                    pts = nil
                }
                let dts: CMTime?
                if CMTIME_IS_VALID(dts_frame) {
                    dts = dts_frame
                }
                else {
                    dts = nil
                }
                
                for writer in encoder.writer {
                    writer?.write_video(PS_stream: elementaryStream, PTS: pts, DTS: dts, keyframe: isIFrame)
                }
            }
        }
    }

}
